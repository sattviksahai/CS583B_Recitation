{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN_IMDB_reviews_reference.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNZQmaLGfcqczGwaCX7Eh0f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sattviksahai/CS583B_Recitation/blob/master/RNN_IMDB_reviews_reference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybCbGJxJ67Jm",
        "colab_type": "text"
      },
      "source": [
        "Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4FYeXSGxyPy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TaTg_hEA7BMr",
        "colab_type": "text"
      },
      "source": [
        "Extract data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JClfCvj-x6vp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar -xf 'drive/My Drive/aclImdb_v1.tar.gz'\n",
        "! rm -rf aclImdb/train/unsup/\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cw6K2qoc7D6L",
        "colab_type": "text"
      },
      "source": [
        "Read Training Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlW9g0YLyZt8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "imdb_dir = './aclImdb'\n",
        "train_dir = os.path.join(imdb_dir, 'train')\n",
        "labels_train = []\n",
        "texts_train = []\n",
        "for label_type in ['pos', 'neg']:\n",
        "  dir_name = os.path.join(train_dir, label_type)\n",
        "  for fname in os.listdir(dir_name):\n",
        "    if fname[-4:] == '.txt':\n",
        "      f = open(os.path.join(dir_name, fname))\n",
        "      texts_train.append(f.read())\n",
        "      f.close()\n",
        "      if label_type == 'neg':\n",
        "        labels_train.append(0)\n",
        "      else:\n",
        "        labels_train.append(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1ybpc2sy4vG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Number of training samples: '+str(len(texts_train)))\n",
        "print('Number of training labels: '+str(len(labels_train)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VuIAwD17MVS",
        "colab_type": "text"
      },
      "source": [
        "Display random review with label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCcBAtm9zGez",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "i=np.random.randint(len(labels_train))\n",
        "print('label #'+str(i)+': '+str(labels_train[i]))\n",
        "print('text #'+str(i)+':')\n",
        "print(texts_train[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glcjZ8F67qGe",
        "colab_type": "text"
      },
      "source": [
        "Tokenize the text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMRKRr9oGZAV",
        "colab_type": "code",
        "outputId": "02f16edd-6f6d-4789-e162-ef04bcb39ed5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "vocabulary = 10000\n",
        "tokenizer = Tokenizer(num_words=vocabulary)\n",
        "tokenizer.fit_on_texts(texts_train)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "sequences_train = tokenizer.texts_to_sequences(texts_train)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBBp2Z8QHxYm",
        "colab_type": "text"
      },
      "source": [
        "Add Padding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tl07PiXIGmq6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import preprocessing\n",
        "\n",
        "word_num = 20\n",
        "x_train_val = preprocessing.sequence.pad_sequences(sequences_train, maxlen=word_num)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaP4aYmxGwME",
        "colab_type": "code",
        "outputId": "f23ea9f8-bb27-40ff-a4f9-119d1fac9b63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(x_train_val.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(25000, 20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZnvDIn7tRqb",
        "colab_type": "text"
      },
      "source": [
        "Training Validation split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r33fJkrwtPq3",
        "colab_type": "code",
        "outputId": "621bd597-de4b-477c-fde2-12340112c835",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "split_ratio = 0.9\n",
        "\n",
        "indices = np.arange(x_train_val.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "x_train = x_train_val[indices[:int(len(indices)*split_ratio)]]\n",
        "x_val = x_train_val[indices[int(len(indices)*split_ratio):]]\n",
        "\n",
        "labels_train = np.array(labels_train)\n",
        "y_train = labels_train[indices[:int(len(indices)*split_ratio)]]\n",
        "y_val = labels_train[indices[int(len(indices)*split_ratio):]]\n",
        "print('Shape of training data: ', x_train.shape)\n",
        "print('Shape of training labels: ', y_train.shape)\n",
        "print('Shape of validation data: ', x_val.shape)\n",
        "print('Shape of validation labels: ', y_val.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of training data:  (22500, 20)\n",
            "Shape of training labels:  (22500,)\n",
            "Shape of validation data:  (2500, 20)\n",
            "Shape of validation labels:  (2500,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xc9u2UYH1ih",
        "colab_type": "text"
      },
      "source": [
        "Define Model\n",
        "Options:\n",
        "a) Simple RNN\n",
        "b) LSTM\n",
        "c) Stacked LSTM\n",
        "d) Bidirectional LSTM\n",
        "e) Conv1D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEacTKEgGz-O",
        "colab_type": "code",
        "outputId": "5668ccd3-8e4b-4fd6-b71c-8b8b0fa86de3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense, Embedding, Flatten, LSTM, Bidirectional, Conv1D\n",
        "\n",
        "embedding_dim = 32\n",
        "h_dim = 32\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocabulary, embedding_dim, input_length=word_num))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 20, 32)            320000    \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 16, 32)            5152      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 16, 1)             33        \n",
            "=================================================================\n",
            "Total params: 325,185\n",
            "Trainable params: 325,185\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5t53-Q2H338",
        "colab_type": "text"
      },
      "source": [
        "Define Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuSevdGWHv7u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import optimizers\n",
        "\n",
        "epochs = 50\n",
        "\n",
        "model.compile(optimizer=optimizers.RMSprop(lr=0.01),\n",
        "            loss='binary_crossentropy', metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ql7sDg7_H62D",
        "colab_type": "text"
      },
      "source": [
        "Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulfs3Ly4IEqm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit(x_train, y_train, epochs=epochs,\n",
        "                    batch_size=16, validation_data=(x_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZ2qCJz2H8yP",
        "colab_type": "text"
      },
      "source": [
        "Visualize training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1QZRtGHIJ3C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "epochs = range(epochs) # 50 is the number of epochs\n",
        "train_acc = history.history['acc']\n",
        "valid_acc = history.history['val_acc']\n",
        "print(train_acc)\n",
        "plt.plot(epochs, train_acc, 'bo', label='Training Accuracy')\n",
        "plt.plot(epochs, valid_acc, 'r', label='Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FQBIzw1WPeU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('imdb_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-_5FfjTiO_R",
        "colab_type": "text"
      },
      "source": [
        "Read Test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LTNxkVz6Eyk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "imdb_dir = './aclImdb'\n",
        "test_dir = os.path.join(imdb_dir, 'test')\n",
        "labels_test = []\n",
        "texts_test = []\n",
        "for label_type in ['pos', 'neg']:\n",
        "  dir_name = os.path.join(test_dir, label_type)\n",
        "  for fname in os.listdir(dir_name):\n",
        "    if fname[-4:] == '.txt':\n",
        "      f = open(os.path.join(dir_name, fname))\n",
        "      texts_test.append(f.read())\n",
        "      f.close()\n",
        "      if label_type == 'neg':\n",
        "        labels_test.append(0)\n",
        "      else:\n",
        "        labels_test.append(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKDn1PK0irgH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Number of training samples: '+str(len(texts_test)))\n",
        "print('Number of training labels: '+str(len(labels_test)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUb7GnV2i04V",
        "colab_type": "text"
      },
      "source": [
        "Tokenize the text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDcWSC_ci0Hk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequences_test = tokenizer.texts_to_sequences(texts_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJ_odwqxjF48",
        "colab_type": "text"
      },
      "source": [
        "Padding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQ_VVj59i850",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test = preprocessing.sequence.pad_sequences(sequences_test, maxlen=word_num)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ckfyyto5jM2A",
        "colab_type": "text"
      },
      "source": [
        "Evaluate model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gcm_vvsjGyr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_and_acc = model.evaluate(x_test, np.array(labels_test))\n",
        "print(\"loss = \",str(loss_and_acc[0]))\n",
        "print(\"acc = \", str(loss_and_acc[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9lekmnFjhSr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}